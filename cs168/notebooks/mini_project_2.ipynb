{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('.venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "b7ad158a3d750b3514d287239b7c964a51055d3f33f34d6339a2cbf40d95c282"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Add '<div class=\"alert alert-block alert-info\">\\n\\n' to the top of markdown cells to mark professor-provided assignment content\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# PRELUDE #\n",
    "###########\n",
    "\n",
    "# auto-reload changed python files\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Format cells with %%black\n",
    "%load_ext blackcellmagic\n",
    "\n",
    "# nice interactive plots\n",
    "%matplotlib inline\n",
    "\n",
    "# add repository directory to include path\n",
    "from pathlib import Path\n",
    "import sys\n",
    "PROJECT_DIR = Path('../..').resolve()\n",
    "sys.path.append(str(PROJECT_DIR))\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "def markdown(s):\n",
    "    return display(Markdown(s))\n",
    "\n",
    "print(\"Add '<div class=\\\"alert alert-block alert-info\\\">\\\\n\\\\n' to the top of markdown cells to mark professor-provided assignment content\")"
   ]
  },
  {
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Part 1: Similarity Metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs168.mini_project_2 import load_data"
   ]
  },
  {
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Goal \n",
    "\n",
    "The goal of this part of the assignment is to understand better the differences between distance\n",
    "metrics, and to think about which metric makes the most sense for a particular application."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Description\n",
    "\n",
    "In this part you will look at the similarity between the posts on various newsgroups. We’ll use the well-known [20 newsgroups dataset](http://qwone.com/~jason/20Newsgroups/). You will use a version of the dataset where every article is represented by a bag-of-words — a vector indexed by words, with each component indicating the number of occurrences of that word. You will need 3 files: `data50.csv`, `label.csv`, and `group.csv`, all of these can be downloaded from the course website. In `data50.csv` there is a sparse representation of the bags-of-words, with each line containing 3 fields: `articleId`, `wordId`, and `count`. To find out which group an article belongs to, use the file `label.csv`, where for `articleId` $i$, line $i$ in `label.csv` contains the `groupId`. Finally the group name is in `group.csv`, with line $i$ containing the name of group $i$.\n",
    "\n",
    "We’ll use the following similarity metrics, where $x$ and $y$ are two bags of words:\n",
    "\n",
    "* Jaccard Similarity: $J(x,y) = \\frac{\\sum_i{min(x_i,y_i)}}{\\sum_i{max(x_i,y_i)}}$\n",
    "* $L_2$ Similarity: $L_2(x,y) = \\|x - y\\|_2 = -\\sqrt{\\sum_i(x_i - y_i)^2}$\n",
    "* Cosine Similarity: $S_C(x, y) = \\frac{\\sum_i{x_i \\cdot y_i}}{\\|x\\|_2 \\cdot \\|y\\|_2}$\n",
    "\n",
    "Note that Jaccard and cosine similarity are numbers between 0 and 1, while $L_2$ similarity is between $-\\infty$ and 0 (with higher numbers indicating more similarity)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "(a) (2 points) Make sure you can import the given datasets into whatever language you’re using. For\n",
    "example, if you’re using python, read the data50.csv file and store the information in an appropriate\n",
    "way. Remember that the total number of words in the corpus is huge, so you might want to work with\n",
    "a sparse representation of your data (e.g., you don’t want to waste space on words that don’t occur in\n",
    "a document). If you’re using MATLAB, you can simply import the data using the GUI."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           count                                                        ...  \\\n",
       "word_id    1     2     3     4     5     6     7     8     9     10     ...   \n",
       "article_id                                                              ...   \n",
       "1            NaN   NaN   1.0   NaN   NaN   NaN   NaN   NaN   NaN   1.0  ...   \n",
       "2            NaN   NaN   NaN   NaN   NaN   NaN   1.0   NaN   NaN   NaN  ...   \n",
       "3            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   1.0  ...   \n",
       "5            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "                                                                        \n",
       "word_id    61058 61059 61060 61061 61062 61063 61064 61065 61066 61067  \n",
       "article_id                                                              \n",
       "1            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "5            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 19575 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"21\" halign=\"left\">count</th>\n    </tr>\n    <tr>\n      <th>word_id</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>61058</th>\n      <th>61059</th>\n      <th>61060</th>\n      <th>61061</th>\n      <th>61062</th>\n      <th>61063</th>\n      <th>61064</th>\n      <th>61065</th>\n      <th>61066</th>\n      <th>61067</th>\n    </tr>\n    <tr>\n      <th>article_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 19575 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "group_names, data, labels = load_data()\n",
    "\n",
    "assert group_names.shape == (20,)\n",
    "assert data.shape == (1000, 19575)\n",
    "assert labels.shape == (1000,)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "(b) (8 points) Implement the three similarity metrics described above. For each metric, prepare the following plot. The plot will look like a 20 × 20 matrix. Rows and columns are index by newsgroups (in the same order). For each entry $(A, B)$ of the matrix (including the diagonal), compute the average similarity over all ways of pairing up one article from $A$ with one article from $B$. After you’ve computed these 400 numbers, plot your results in a heatmap. Make sure that you label your axes with the group\n",
    "names and pick an appropriate colormap to represent the data: the rainbow colormap may look fancy, but a simple color map from white to blue may be a lot more insightful. Make sure to include a legend. (Note that the computation might take five or ten minutes, but shouldn’t take much more.)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "(c) (4 points) Based on your three heatmaps, which of the similarity metrics seems the most reasonable, and why would you expect that/those metrics to be better suited to this data?\n",
    "\n",
    "Are there any pairs of newsgroups that are very similar?\n",
    "\n",
    "Would you have expected these to be similar?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Parts 2 and 3: A nearest-neighbor classification system"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "A “nearest-neighbor” classification system is conceptually extremely simple, and often is very effective. Given a large dataset of labeled examples, a nearest-neighbor classification system will predict a label for a new example, $x$, as follows: it will find the element of the labeled dataset that is closest to $x$—closest in whatever metric makes the most sense for that dataset—and then output the label of this closest point. \\[As you can imagine, there are many natural extensions of this system—for example considering the labels of the $r > 1$ closest neighbors.]\n",
    "\n",
    "From a computational standpoint, naively, finding the closest point to $x$ might be time consuming if the\n",
    "labeled dataset is large, or the points are very high dimensional. In the next two parts, you will explore two\n",
    "ways of speeding up this computation: dimension reduction, and via locality sensitive hashing."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Part 2: Dimension Reduction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### Goal\n",
    "The goal of this part is to get a feel for the trade-off in dimensionality reduction between the quality\n",
    "of approximation and the number of dimensions used."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Description\n",
    "\n",
    "You may have noticed that it takes some time to compute all the distances in the previous part (though it should not take more than a minute or two). In this part we will implement a dimension reduction technique to reduce the running time, which can be used to also speed up classification.\n",
    "\n",
    "In the following, $k$ will refer to the original dimension of your data, and $d$ will refer to the target dimension.\n",
    "\n",
    "* Random Projection: Given a set of $k$-dimensional vectors $\\{v1, v2, \\dots\\}$, define a $d × k$ matrix $M$ by drawing each entry randomly (and independently) from a normal distribution of mean 0 and variance 1. The $d$-dimensional reduced vector corresponding to $v_i$\n",
    "is given by the matrix-vector product $Mv_i$.\n",
    "We can think of the matrix $M$ as a set of $d$ random $k$-dimensional vectors $\\{w1, \\dots , wd\\}$ (the rows\n",
    "of $M$), and then the $j$th coordinate of the reduced vector $Mv_i$ is the inner product between that $v_i$ and $w_j$. If you need to review the basics of matrix-vector multiplication, see the primer on the course webpage."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}